{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Off-Policy-Learning-with-Importance-Sampling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN1TJPNr3VcxSO2WBg/sOcp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shangeth/Monte-Carlo-Prediction/blob/master/Off_Policy_Learning_with_Importance_Sampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oew_X1sC_qHb",
        "colab_type": "text"
      },
      "source": [
        "# Off-Policy Monte Carlo with Importance Sampling\n",
        "## Off Policy Learning\n",
        "\n",
        "By exploration-exploitation trade-off, the agent should take sub-optimal exploratory action by which the agent may receive less reward. One way of exploration is by using an epsilon-greedy policy, where the agent takes a nongreedy action with a small probability.\n",
        "\n",
        "In an on-policy, improvement and evaluation are done on the policy which is used to select actions.\n",
        "\n",
        "In off-policy, improvement and evaluation are done on a different policy from the one used to select actions. the policy learned is off the policy used for action selection while gathering episodes.\n",
        "\n",
        "- Target Policy $\\pi(a/s)$ : The value function of learning is based on $\\pi(a/s)$. We want the target policy to be the optimal policy $\\pi^{*}(a/s)$. The target policy will be used for action selection after the learning process is complete(deployment).\n",
        "- Behavior Policy $b(a/s)$: Behavior policy is used for action selection while gathering episodes to train the agent. This generally follows an exploratory policy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stg4_5fC7GKi",
        "colab_type": "text"
      },
      "source": [
        "## Importance Sampling\n",
        "\n",
        "We have a random variable $x \\sim b$ sampled from behavior policy distribution $b$. We want to estimate the expected value of $x$ wrt the target distribution $\\pi$ ie: $E_{\\pi}[X]$. The sample average will give the expected value of x under b $E_{b}[X]$.\n",
        "\n",
        "$E_{\\pi}[X] = \\sum x \\pi(x)$ where $x \\in X$\n",
        "\n",
        "$ \\qquad = \\sum x \\pi(x) \\dfrac{b(x)}{b(x)}$\n",
        "\n",
        "$ \\qquad = \\sum x \\dfrac{\\pi(x)}{b(x)} b(x)$\n",
        "\n",
        "$ \\qquad = \\sum x \\rho(x) b(x)$ \n",
        "\n",
        "where $\\rho(x) = \\dfrac{\\pi(x)}{b(x)}$ and is called the importance sampling ratio.\n",
        "\n",
        "\\\n",
        "Let $x\\rho(x)$ be a new random variable $X_\\rho(X)$.\n",
        "Then, $E_{\\pi}[X] = \\sum x \\rho(x) b(x) = E_{b}[X_{\\rho}(X)]$. Now we have expectation under $b$ instead of $\\pi$.\n",
        "\n",
        "\\\n",
        "### How do we estimating expectation from the data? \n",
        "Compute the weighted sample average with importance sampling ratio as the weights.\n",
        "$E_{\\pi}[X] = \\sum x \\rho(x) b(x) = E_{b}[X_{\\rho}(X)] \\approx \\dfrac{1}{n}\\sum_{i=1}^{n}x_i \\rho(x_i)$ and $x_i \\sim b$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtDmO2Yv7KXO",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Off Policy Monte Carlo Prediction with Importance Sampling\n",
        "\n",
        "In Monte Carlo prediction, we estimate the value of each state by computing a sample average over returns starting from that state. $V_{\\pi}(s) = E_{\\pi}[G_t|S_t=s]$\n",
        "\n",
        "\\\n",
        "In off-policy, we are trying to estimate value under the target policy $\\pi(s)$ using returns following the behavior policy $b(s)$. As discussed above, we need to find the value of $\\rho$ for each of the sampled returns. $\\rho$ is the probability of trajectory under $\\pi$ divided by the probability of trajectory under $b$.\n",
        "\n",
        "$V_{\\pi}(s) = E_{b}[\\rho G_t|S_t=s]$ ; $\\rho = \\dfrac{P(trajectory\\ under\\ \\pi)}{P(trajectory\\ under\\ b)}$\n",
        "\n",
        "\\\n",
        "The probaility of a trajectory under a policy can be given by\n",
        "$P(trajectory\\ under\\ policy) = P(A_t, S_{t+1}, A_{t+1}, ..., S_T| S_t, A_{t:T})$\n",
        "\n",
        "where all actions are taken under the policy $b$.\n",
        "\n",
        "\\\n",
        "As this is a Markov process, we can split the probability terms into\n",
        "\n",
        "$P(A_t, S_{t+1}, A_{t+1}, ..., S_T| S_t, A_{t:T}) = b(A_t|S_t)p(S_{t+1}|S_t, A_t)*b(A_{t+1}|S_{t+1}) p(S_{t+2}|S_{t+1}, A_{t+1})*...p(S_{T}|S_{T-1}, A_{T-1})$\n",
        "\n",
        "\\\n",
        "$b(A_t|S_t)p(S_{t+1}|S_t, A_t)$ give the probability of action $A_t$ at state $S_t$ times the probability of the state transition to state $S_{t+1}$\n",
        "\n",
        "$P(A_t, S_{t+1}, A_{t+1}, ..., S_T| S_t, A_{t:T}) = \\prod_{k=1}^{T} b(A_k|S_k)p(S_{k+1}|S_k, A_k)$\n",
        "\n",
        "\n",
        "$\\rho = \\dfrac{P(trajectory\\ under\\ \\pi)}{P(trajectory\\ under\\ b)}$\n",
        "\n",
        "$\\quad = \\prod_{k=t}^{T-1}\\dfrac{\\pi(A_k|S_k)p(S_{k+1}|S_k, A_k)}{b(A_k|S_k)p(S_{k+1}|S_k, A_k)}$\n",
        "\n",
        "$\\rho = \\prod_{k=t}^{T-1}\\dfrac{\\pi(A_k|S_k)}{b(A_k|S_k)}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSvvBKDn8XAH",
        "colab_type": "text"
      },
      "source": [
        "## Incremental Implementation of Off-policy MC\n",
        "\n",
        "Suppose we have a sequence of returns $G_1, G_2, ...G_{n-1}$ all starting in the same state and with corresponding weights $W_i$, then the weighted average of returns $V_n = \\dfrac{\\sum_{k=1}^{n-1} W_kG_k}{\\sum_{k=1}^{n-1} W_k}$ , $n \\geq 2$ and the cumulative sum of weights $C_{n+1} = C_n + W_{n+1}$ where $C_0 = 0$.\n",
        "\n",
        "The update rule for $V_{n+1} = V_n + \\dfrac{W_n}{C_n}[G_n-V_n]$, $n \\geq 1$ and $V_1$ is arbitrary.\n",
        "\n",
        "Here $W_n$ will be the importance sampling weight."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5znOS4nEGSW_",
        "colab_type": "text"
      },
      "source": [
        "## Greedy $\\pi$ policy\n",
        "When the target policy $\\pi$ is $\\epsilon$ greedy, it is determenistic and $\\pi(A_t/S_t) = 1$ . So $\\rho = \\prod_{k=t}^{T-1}\\dfrac{1}{b(A_k|S_k)}$ and $W$ can be updated with $W \\leftarrow W \\dfrac{1}{b(A_t|S_t)}$ for each time step in the trajectory.\n",
        "\n",
        "So the Off policy Monte Carlo Control algorithm is\n",
        "![](https://i.stack.imgur.com/Xi0vX.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81WGFwjmGdDu",
        "colab_type": "text"
      },
      "source": [
        "# Off-Policy MC Control with Weighted Importance in Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eUqx_OVGsgT",
        "colab_type": "text"
      },
      "source": [
        "## BlackJack Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49fKvqny_t2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import gym\n",
        "import numpy as np\n",
        "from collections import defaultdict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qLkSdg_GxZv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "97f78405-d378-44d6-93bd-b038fd84c4f1"
      },
      "source": [
        "env = gym.make('Blackjack-v0')\n",
        "\n",
        "print(vars(env), end='\\n\\n')\n",
        "print(dir(env))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'action_space': Discrete(2), 'observation_space': Tuple(Discrete(32), Discrete(11), Discrete(2)), 'np_random': RandomState(MT19937) at 0x7FE1148D2888, 'natural': False, 'dealer': [10, 1], 'player': [10, 1], 'spec': EnvSpec(Blackjack-v0)}\n",
            "\n",
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_get_obs', 'action_space', 'close', 'dealer', 'metadata', 'natural', 'np_random', 'observation_space', 'player', 'render', 'reset', 'reward_range', 'seed', 'spec', 'step', 'unwrapped']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf6Dg3AfG4gl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0a610258-e65e-4d66-e237-583ded33b16a"
      },
      "source": [
        "print(env.observation_space)\n",
        "print(env.action_space)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tuple(Discrete(32), Discrete(11), Discrete(2))\n",
            "Discrete(2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSicC_S6G71P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e9e7a5cd-8a6b-41ae-a454-89268edf16be"
      },
      "source": [
        "random_state = env.reset()\n",
        "print('Random State', random_state)\n",
        "\n",
        "random_action = env.action_space.sample()\n",
        "print('Random Action', random_action)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random State (18, 2, False)\n",
            "Random Action 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4fqW7eGHH2x",
        "colab_type": "text"
      },
      "source": [
        "## Generate Random Eposides"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COOOYzTzG__T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "9ddb2495-14f7-4fe5-9398-43fe1c58a72c"
      },
      "source": [
        "num_episodes = 3\n",
        "\n",
        "for i in range(num_episodes):\n",
        "    print('Episode : ', i+1)\n",
        "    state = env.reset()\n",
        "    step = 0\n",
        "    while True:\n",
        "        step +=1\n",
        "        action = env.action_space.sample()\n",
        "        print('Step = {}\\t State = {}\\t Action Taken = {}'.format(step, state, action))\n",
        "        state, reward, done, info = env.step(action)\n",
        "        if done:\n",
        "            print('Game Ended...')\n",
        "            if reward > 0: print('Agent Won!\\n')\n",
        "            else: print('Agent Lost!\\n')\n",
        "            break"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode :  1\n",
            "Step = 1\t State = (10, 7, False)\t Action Taken = 1\n",
            "Step = 2\t State = (21, 7, True)\t Action Taken = 1\n",
            "Step = 3\t State = (15, 7, False)\t Action Taken = 1\n",
            "Step = 4\t State = (18, 7, False)\t Action Taken = 0\n",
            "Game Ended...\n",
            "Agent Lost!\n",
            "\n",
            "Episode :  2\n",
            "Step = 1\t State = (20, 8, False)\t Action Taken = 0\n",
            "Game Ended...\n",
            "Agent Won!\n",
            "\n",
            "Episode :  3\n",
            "Step = 1\t State = (12, 7, False)\t Action Taken = 1\n",
            "Step = 2\t State = (15, 7, False)\t Action Taken = 0\n",
            "Game Ended...\n",
            "Agent Won!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqsV12UeNqBW",
        "colab_type": "text"
      },
      "source": [
        "## Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR-4Zh-1HM5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_policy(nA):\n",
        "    A = np.ones(nA, dtype=float) / nA\n",
        "    def policy_fn(observation):\n",
        "        return A\n",
        "    return policy_fn\n",
        "    \n",
        "def greedy_policy(Q):\n",
        "    def policy_fn(state):\n",
        "        A = np.zeros_like(Q[state], dtype=float)\n",
        "        best_action = np.argmax(Q[state])\n",
        "        A[best_action] = 1.0\n",
        "        return A\n",
        "    return policy_fn\n",
        "    \n",
        "def mc_off_policy(env, num_episodes, behavior_policy, max_time=100, discount_factor=1.0):\n",
        "    Q = defaultdict(lambda:np.zeros(env.action_space.n))\n",
        "    C = defaultdict(lambda:np.zeros(env.action_space.n))\n",
        "\n",
        "    target_policy = greedy_policy(Q)\n",
        "\n",
        "    for i_episode in range(1, num_episodes+1):\n",
        "        if i_episode % 1000 == 0:\n",
        "            print(\"\\rEpisode {}/{}.\".format(i_episode, num_episodes), end=\"\")\n",
        "            sys.stdout.flush()\n",
        "\n",
        "        episode = []\n",
        "        state = env.reset()\n",
        "        for t in range(max_time):\n",
        "            probs = behavior_policy(state)\n",
        "            action = np.random.choice(np.arange(len(probs)), p=probs)\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            episode.append((state, action, reward))\n",
        "            if done:\n",
        "                break\n",
        "            state = next_state\n",
        "        \n",
        "        G = 0.0\n",
        "        W = 1.0\n",
        "        for t in range(len(episode))[::-1]:\n",
        "            state, action, reward = episode[t]\n",
        "            G = discount_factor * G + reward\n",
        "            C[state][action] += W\n",
        "            Q[state][action] += (W / C[state][action]) * (G - Q[state][action])\n",
        "            if action !=  np.argmax(target_policy(state)):\n",
        "                break\n",
        "            W = W * 1./behavior_policy(state)[action]\n",
        "    return Q, target_policy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TIVjWz7JZsv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "066e3ba8-1782-4787-9dcb-1b6f77f72b25"
      },
      "source": [
        "random_policy = random_policy(env.action_space.n)\n",
        "Q, policy = mc_off_policy(env, num_episodes=500000, behavior_policy=random_policy)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode 500000/500000."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-JI56CiNv4t",
        "colab_type": "text"
      },
      "source": [
        "## Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnhabVkSJnzy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "\n",
        "def plot_policy(policy):\n",
        "\n",
        "    def get_Z(x, y, usable_ace):\n",
        "        if (x,y,usable_ace) in policy:\n",
        "            return policy[x,y,usable_ace]\n",
        "        else:\n",
        "            return 1\n",
        "\n",
        "    def get_figure(usable_ace, ax):\n",
        "        x_range = np.arange(11, 22)\n",
        "        y_range = np.arange(10, 0, -1)\n",
        "        X, Y = np.meshgrid(x_range, y_range)\n",
        "        Z = np.array([[get_Z(x,y,usable_ace) for x in x_range] for y in y_range])\n",
        "        surf = ax.imshow(Z, cmap=plt.get_cmap('Pastel2', 2), vmin=0, vmax=1, extent=[10.5, 21.5, 0.5, 10.5])\n",
        "        plt.xticks(x_range)\n",
        "        plt.yticks(y_range)\n",
        "        plt.gca().invert_yaxis()\n",
        "        ax.set_xlabel('Player\\'s Current Sum')\n",
        "        ax.set_ylabel('Dealer\\'s Showing Card')\n",
        "        ax.grid(color='w', linestyle='-', linewidth=1)\n",
        "        divider = make_axes_locatable(ax)\n",
        "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
        "        cbar = plt.colorbar(surf, ticks=[0,1], cax=cax)\n",
        "        cbar.ax.set_yticklabels(['0 (STICK)','1 (HIT)'])\n",
        "            \n",
        "    fig = plt.figure(figsize=(15, 15))\n",
        "    ax = fig.add_subplot(121)\n",
        "    ax.set_title('Usable Ace')\n",
        "    get_figure(True, ax)\n",
        "    ax = fig.add_subplot(122)\n",
        "    ax.set_title('No Usable Ace')\n",
        "    get_figure(False, ax)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJtjvyfaKYf_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "17205553-b33d-40b8-e641-86258d3e4d88"
      },
      "source": [
        "policy = dict((k,np.argmax(v)) for k, v in Q.items())\n",
        "plot_policy(policy)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6kAAAGACAYAAABP4yRkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZIkqTMcUiVJkiRJnfH/AE6E3Kdkc3VEAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x1080 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}